#!/usr/bin/env python3
"""
å­£åº¦è´¡çŒ®è€…ç»Ÿè®¡è„šæœ¬
åŠŸèƒ½ï¼šç»Ÿè®¡æŒ‡å®šå­£åº¦å†…æ‰€æœ‰æˆå‘˜çš„æœ‰æ•ˆè´¡çŒ®ï¼Œå¹¶æŒ‰ç­‰çº§åˆ†ç±»
- ä¼˜ç§€è´¡çŒ®è€…ï¼šæœ‰æ•ˆcommit >= 10æ¬¡
- å“è¶Šè´¡çŒ®è€…ï¼šæœ‰æ•ˆcommit >= 50æ¬¡
- æœ‰æ•ˆcommitå®šä¹‰ï¼šè‡³å°‘åŒ…å«ä¸€ä¸ªæ–‡ä»¶æ–°å¢è¡Œæ•° >= 10è¡Œ

ä¼˜åŒ–ç‰¹æ€§ï¼š
1. æœ¬åœ°ç¼“å­˜æœºåˆ¶ - é¿å…é‡å¤APIè°ƒç”¨
2. å¢é‡æ›´æ–° - åªå¤„ç†æ–°çš„commit
3. è¿›åº¦æ˜¾ç¤º - å®æ—¶æ˜¾ç¤ºå¤„ç†è¿›åº¦
4. JSONè¾“å‡º - ç”Ÿæˆå‰ç«¯å¯ç”¨çš„æ•°æ®æ ¼å¼
5. æœºå™¨äººè¿‡æ»¤ - ä½¿ç”¨å…±äº«çš„è¿‡æ»¤è§„åˆ™
"""

import os
import json
import time
import sys
import re
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from collections import defaultdict
import requests

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥å…±äº«æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent.parent))
from bot_filter import is_bot_account

# é…ç½®
CONFIG = {
    'GITHUB_TOKEN': os.getenv('GITHUB_TOKEN') or os.getenv('GITHUB_KEY'),
    'ORG_NAME': 'datawhalechina',
    'API_BASE': 'https://api.github.com',
    # ç¼“å­˜ç›®å½• (ç›¸å¯¹äº scripts/quarterly_contributors/)
    'CACHE_DIR': Path(__file__).parent.parent.parent / 'cache' / 'quarterly_stats',
    # è¾“å‡ºç›®å½•
    'OUTPUT_DIR': Path(__file__).parent.parent.parent / 'docs' / 'public' / 'data' / 'datawhalechina',
    # æœ‰æ•ˆcommitçš„é˜ˆå€¼ï¼ˆå•æ–‡ä»¶æ–°å¢è¡Œæ•°ï¼‰
    'VALID_COMMIT_THRESHOLD': 10,
    # è´¡çŒ®è€…ç­‰çº§é˜ˆå€¼
    'EXCELLENT_THRESHOLD': 10,  # ä¼˜ç§€è´¡çŒ®è€…
    'OUTSTANDING_THRESHOLD': 50,  # å“è¶Šè´¡çŒ®è€…
    # APIè°ƒç”¨æ§åˆ¶
    'MAX_RETRIES': 3,
    'RETRY_DELAY': 2,
    'REQUEST_DELAY': 0.1,  # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
}


def get_headers():
    """è·å–APIè¯·æ±‚å¤´"""
    headers = {
        'Accept': 'application/vnd.github+json',
        'X-GitHub-Api-Version': '2022-11-28',
        'User-Agent': 'quarterly-contributors-bot'
    }
    if CONFIG['GITHUB_TOKEN']:
        headers['Authorization'] = f"Bearer {CONFIG['GITHUB_TOKEN']}"
    return headers


def extract_username_from_email(email):
    """
    å°è¯•ä»é‚®ç®±ä¸­æå–GitHubç”¨æˆ·å
    æ”¯æŒçš„æ ¼å¼ï¼š
    - 12345678+username@users.noreply.github.com
    - username@users.noreply.github.com
    """
    if not email:
        return None

    # GitHub noreply é‚®ç®±æ ¼å¼
    noreply_pattern = r'^(?:\d+\+)?([^@]+)@users\.noreply\.github\.com$'
    match = re.match(noreply_pattern, email, re.IGNORECASE)
    if match:
        return match.group(1)

    return None


def search_user_by_email(email):
    """
    é€šè¿‡é‚®ç®±æœç´¢GitHubç”¨æˆ·
    æ³¨æ„ï¼šè¿™ä¼šæ¶ˆè€—é¢å¤–çš„APIè°ƒç”¨
    """
    if not email or '@' not in email:
        return None

    # è·³è¿‡æ˜æ˜¾æ— æ•ˆçš„é‚®ç®±
    if 'noreply' in email.lower() or 'localhost' in email.lower():
        return None

    url = f"{CONFIG['API_BASE']}/search/users?q={email}+in:email"
    try:
        data = fetch_api(url)
        if data and data.get('total_count', 0) == 1:
            # åªæœ‰ç²¾ç¡®åŒ¹é…ä¸€ä¸ªç”¨æˆ·æ—¶æ‰è¿”å›
            return data['items'][0]['login']
    except Exception:
        pass

    return None


def check_rate_limit():
    """æ£€æŸ¥APIé€Ÿç‡é™åˆ¶"""
    url = f"{CONFIG['API_BASE']}/rate_limit"
    try:
        response = requests.get(url, headers=get_headers(), timeout=10)
        if response.status_code == 200:
            data = response.json()
            core = data['resources']['core']
            remaining = core['remaining']
            limit = core['limit']
            reset_time = datetime.fromtimestamp(core['reset'])

            print(f"ğŸ“Š APIé€Ÿç‡é™åˆ¶: {remaining}/{limit} å‰©ä½™")
            print(f"â° é‡ç½®æ—¶é—´: {reset_time.strftime('%Y-%m-%d %H:%M:%S')}")

            if remaining < 100:
                print(f"âš ï¸  è­¦å‘Š: APIè°ƒç”¨æ¬¡æ•°ä¸è¶³100æ¬¡ï¼Œå»ºè®®ç­‰å¾…é‡ç½®")
                return False
            return True
    except Exception as e:
        print(f"âŒ æ£€æŸ¥é€Ÿç‡é™åˆ¶å¤±è´¥: {e}")
        return True  # ç»§ç»­æ‰§è¡Œ


def fetch_api(url, retries=None):
    """å‘é€APIè¯·æ±‚ï¼ˆå¸¦é‡è¯•å’Œé€Ÿç‡é™åˆ¶å¤„ç†ï¼‰"""
    if retries is None:
        retries = CONFIG['MAX_RETRIES']

    for attempt in range(retries):
        try:
            time.sleep(CONFIG['REQUEST_DELAY'])
            response = requests.get(url, headers=get_headers(), timeout=30)

            # æ£€æŸ¥é€Ÿç‡é™åˆ¶
            remaining = response.headers.get('X-RateLimit-Remaining')
            if remaining and int(remaining) < 10:
                reset_time = int(response.headers.get('X-RateLimit-Reset', 0))
                wait_time = max(reset_time - int(time.time()), 0) + 1
                print(f"â³ APIé€Ÿç‡é™åˆ¶æ¥è¿‘ï¼Œç­‰å¾… {wait_time} ç§’...")
                time.sleep(wait_time)
                continue

            response.raise_for_status()
            return response.json()

        except requests.exceptions.HTTPError as e:
            if response.status_code == 403:
                print(f"âŒ APIé€Ÿç‡é™åˆ¶æˆ–æƒé™é—®é¢˜")
                return None
            elif response.status_code == 404:
                return None
            print(f"âš ï¸  HTTPé”™è¯¯ {response.status_code}: {e}")

        except Exception as e:
            print(f"âš ï¸  è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{retries}): {e}")

        if attempt < retries - 1:
            wait_time = CONFIG['RETRY_DELAY'] * (2 ** attempt)
            print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
            time.sleep(wait_time)

    return None


def get_quarter_date_range(year, quarter):
    """
    è·å–æŒ‡å®šå­£åº¦çš„æ—¥æœŸèŒƒå›´

    Args:
        year: å¹´ä»½
        quarter: å­£åº¦ (1-4)

    Returns:
        (start_date, end_date) ISOæ ¼å¼å­—ç¬¦ä¸²
    """
    quarter_months = {
        1: (1, 3),
        2: (4, 6),
        3: (7, 9),
        4: (10, 12)
    }

    start_month, end_month = quarter_months[quarter]
    start_date = datetime(year, start_month, 1)

    # è®¡ç®—å­£åº¦ç»“æŸæ—¥æœŸï¼ˆä¸‹ä¸ªå­£åº¦ç¬¬ä¸€å¤©ï¼‰
    if quarter == 4:
        end_date = datetime(year + 1, 1, 1)
    else:
        end_date = datetime(year, end_month + 1, 1)

    return (
        start_date.strftime('%Y-%m-%dT%H:%M:%SZ'),
        end_date.strftime('%Y-%m-%dT%H:%M:%SZ')
    )


class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨ - ç®¡ç†commitè¯¦æƒ…çš„æœ¬åœ°ç¼“å­˜"""

    def __init__(self, cache_dir):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.cache_file = self.cache_dir / 'commit_details.json'
        self.cache = self._load_cache()

    def _load_cache(self):
        """åŠ è½½ç¼“å­˜"""
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸  åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
                return {}
        return {}

    def get(self, repo, sha):
        """è·å–ç¼“å­˜çš„commitè¯¦æƒ…"""
        key = f"{repo}:{sha}"
        return self.cache.get(key)

    def set(self, repo, sha, data):
        """è®¾ç½®ç¼“å­˜"""
        key = f"{repo}:{sha}"
        self.cache[key] = data

    def save(self):
        """ä¿å­˜ç¼“å­˜åˆ°æ–‡ä»¶"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ç¼“å­˜å·²ä¿å­˜: {len(self.cache)} æ¡è®°å½•")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

    def size(self):
        """è¿”å›ç¼“å­˜å¤§å°"""
        return len(self.cache)

    def clear(self):
        """æ¸…ç†ç¼“å­˜ç›®å½•"""
        try:
            if self.cache_dir.exists():
                shutil.rmtree(self.cache_dir)
                print(f"ğŸ—‘ï¸  ç¼“å­˜ç›®å½•å·²æ¸…ç†: {self.cache_dir}")
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")


def get_org_repos(org_name):
    """è·å–ç»„ç»‡çš„æ‰€æœ‰å…¬å¼€ä»“åº“"""
    print(f"\nğŸ“ è·å–ç»„ç»‡ {org_name} çš„ä»“åº“åˆ—è¡¨...")
    all_repos = []
    page = 1

    while True:
        url = f"{CONFIG['API_BASE']}/orgs/{org_name}/repos?per_page=100&page={page}&type=public&sort=updated"
        repos = fetch_api(url)

        if not repos or len(repos) == 0:
            break

        # è¿‡æ»¤forkä»“åº“
        original_repos = [repo for repo in repos if not repo.get('fork', False)]
        all_repos.extend(original_repos)

        print(f"  âœ“ ç¬¬{page}é¡µ: {len(original_repos)} ä¸ªåŸåˆ›ä»“åº“")

        if len(repos) < 100:
            break

        page += 1

    print(f"âœ… æ€»å…±æ‰¾åˆ° {len(all_repos)} ä¸ªä»“åº“")
    return all_repos


def get_commits_in_range(org_name, repo_name, since, until):
    """è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„commits"""
    url = f"{CONFIG['API_BASE']}/repos/{org_name}/{repo_name}/commits"
    params = {
        'since': since,
        'until': until,
        'per_page': 100
    }

    all_commits = []
    page = 1

    while True:
        page_url = f"{url}?since={params['since']}&until={params['until']}&per_page={params['per_page']}&page={page}"
        commits = fetch_api(page_url)

        if not commits or len(commits) == 0:
            break

        all_commits.extend(commits)

        if len(commits) < 100:
            break

        page += 1

    return all_commits


def get_commit_details(org_name, repo_name, sha, cache_manager):
    """è·å–commitçš„è¯¦ç»†ä¿¡æ¯ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    # å…ˆæ£€æŸ¥ç¼“å­˜
    cached = cache_manager.get(repo_name, sha)
    if cached:
        return cached

    # ä»APIè·å–
    url = f"{CONFIG['API_BASE']}/repos/{org_name}/{repo_name}/commits/{sha}"
    data = fetch_api(url)

    if data:
        # æå–éœ€è¦çš„ä¿¡æ¯
        details = {
            'sha': sha[:8],
            'author': data['commit']['author']['name'],
            'author_email': data['commit']['author'].get('email', ''),
            'author_login': data['author']['login'] if data.get('author') else None,
            'date': data['commit']['author']['date'],
            'message': data['commit']['message'].split('\n')[0][:100],
            'files': []
        }

        # æå–æ–‡ä»¶å˜æ›´ä¿¡æ¯
        if 'files' in data:
            for file in data['files']:
                details['files'].append({
                    'filename': file['filename'],
                    'additions': file.get('additions', 0),
                    'deletions': file.get('deletions', 0),
                    'changes': file.get('changes', 0)
                })

        # ç¼“å­˜ç»“æœ
        cache_manager.set(repo_name, sha, details)
        return details

    return None


def is_valid_commit(commit_details):
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆcommit
    æœ‰æ•ˆcommitå®šä¹‰ï¼šè‡³å°‘æœ‰ä¸€ä¸ªæ–‡ä»¶çš„æ–°å¢è¡Œæ•° >= é˜ˆå€¼
    """
    if not commit_details or 'files' not in commit_details:
        return False

    threshold = CONFIG['VALID_COMMIT_THRESHOLD']
    for file in commit_details['files']:
        if file.get('additions', 0) >= threshold:
            return True

    return False


def process_repository(org_name, repo_name, since, until, cache_manager, stats):
    """
    å¤„ç†å•ä¸ªä»“åº“çš„ç»Ÿè®¡

    Args:
        org_name: ç»„ç»‡åç§°
        repo_name: ä»“åº“åç§°
        since: å¼€å§‹æ—¶é—´
        until: ç»“æŸæ—¶é—´
        cache_manager: ç¼“å­˜ç®¡ç†å™¨
        stats: ç»Ÿè®¡æ•°æ®å­—å…¸ï¼ˆä¼šè¢«ä¿®æ”¹ï¼‰

    Returns:
        å¤„ç†çš„commitæ•°é‡
    """
    print(f"\n  ğŸ“¦ å¤„ç†ä»“åº“: {repo_name}")

    # è·å–æ—¶é—´èŒƒå›´å†…çš„commits
    commits = get_commits_in_range(org_name, repo_name, since, until)
    if not commits:
        print(f"    â„¹ï¸  æ— commit")
        return 0

    print(f"    âœ“ æ‰¾åˆ° {len(commits)} ä¸ªcommit")

    valid_count = 0
    processed_count = 0

    for i, commit in enumerate(commits):
        sha = commit['sha']
        # ä»åˆ—è¡¨APIä¸­æå–author loginï¼ˆåˆ—è¡¨APIæœ‰æ—¶èƒ½å…³è”åˆ°ç”¨æˆ·ï¼Œè¯¦æƒ…APIå´ä¸è¡Œï¼‰
        list_author_login = commit.get('author', {}).get('login') if commit.get('author') else None

        # è·å–commitè¯¦æƒ…
        details = get_commit_details(org_name, repo_name, sha, cache_manager)
        if not details:
            continue

        processed_count += 1

        # åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆcommit
        if is_valid_commit(details):
            valid_count += 1

            # è·å–ä½œè€…ä¿¡æ¯ - å¤šç§æ–¹å¼å°è¯•è§£æGitHubç”¨æˆ·å
            author_login = details.get('author_login')
            is_verified = True

            # æ–¹å¼1: ä½¿ç”¨åˆ—è¡¨APIä¸­çš„author login
            if not author_login and list_author_login:
                author_login = list_author_login

            # æ–¹å¼2: ä»é‚®ç®±ä¸­æå–ç”¨æˆ·åï¼ˆGitHub noreplyæ ¼å¼ï¼‰
            if not author_login:
                author_email = details.get('author_email', '')
                author_login = extract_username_from_email(author_email)
                if author_login:
                    print(f"    ğŸ“§ ä»é‚®ç®±è§£æç”¨æˆ·å: {author_login}")

            # æ–¹å¼3: é€šè¿‡é‚®ç®±æœç´¢GitHubç”¨æˆ·ï¼ˆæ¶ˆè€—é¢å¤–APIï¼‰
            if not author_login:
                author_email = details.get('author_email', '')
                if author_email and '@' in author_email:
                    author_login = search_user_by_email(author_email)
                    if author_login:
                        print(f"    ğŸ” é€šè¿‡é‚®ç®±æœç´¢åˆ°ç”¨æˆ·: {author_login}")

            # æ–¹å¼4: æ— æ³•è§£æï¼Œä½¿ç”¨commitä½œè€…åï¼Œæ ‡è®°ä¸ºæœªéªŒè¯
            if not author_login:
                author_login = details.get('author', 'Unknown')
                is_verified = False
                print(f"    âš ï¸  æœªèƒ½è§£æGitHubç”¨æˆ·åï¼Œä½¿ç”¨ä½œè€…å: {author_login}")

            # æ£€æŸ¥æ˜¯å¦ä¸ºæœºå™¨äººè´¦æˆ·ï¼ˆä½¿ç”¨å…±äº«çš„è¿‡æ»¤è§„åˆ™ï¼‰
            if is_bot_account(author_login):
                print(f"    ğŸ¤– è·³è¿‡æœºå™¨äººè´¦æˆ·: {author_login}")
                continue

            # è®°å½•åˆ°ç»Ÿè®¡æ•°æ®
            if author_login not in stats:
                stats[author_login] = {
                    'username': author_login,
                    'verified': is_verified,
                    'valid_commits': 0,
                    'total_commits': 0,
                    'repos': set(),
                    'commits_detail': []
                }
            # å¦‚æœä¹‹å‰æ˜¯æœªéªŒè¯çš„ï¼Œç°åœ¨æœ‰éªŒè¯çš„commitï¼Œæ›´æ–°ä¸ºå·²éªŒè¯
            elif is_verified and not stats[author_login].get('verified'):
                stats[author_login]['verified'] = True

            stats[author_login]['valid_commits'] += 1
            stats[author_login]['total_commits'] += 1
            stats[author_login]['repos'].add(repo_name)
            stats[author_login]['commits_detail'].append({
                'repo': repo_name,
                'sha': details['sha'],
                'message': details['message'],
                'date': details['date'],
                'files_count': len(details['files']),
                'total_additions': sum(f['additions'] for f in details['files'])
            })

        # æ˜¾ç¤ºè¿›åº¦
        if (i + 1) % 50 == 0:
            print(f"    ğŸ“Š è¿›åº¦: {i + 1}/{len(commits)} commits")

    print(f"    âœ… æœ‰æ•ˆcommit: {valid_count}/{processed_count}")
    return processed_count


def classify_contributors(stats):
    """
    å¯¹è´¡çŒ®è€…è¿›è¡Œåˆ†çº§

    Returns:
        {
            'outstanding': [...],  # å“è¶Šè´¡çŒ®è€… (>=50)
            'excellent': [...],    # ä¼˜ç§€è´¡çŒ®è€… (>=10)
            'active': [...]        # æ´»è·ƒè´¡çŒ®è€… (<10)
        }
    """
    outstanding = []
    excellent = []
    active = []

    for username, data in stats.items():
        valid_commits = data['valid_commits']

        contributor = {
            'username': username,
            'verified': data.get('verified', True),
            'valid_commits': valid_commits,
            'total_commits': data['total_commits'],
            'repos_count': len(data['repos']),
            'repos': sorted(list(data['repos'])),
            'recent_commits': sorted(
                data['commits_detail'],
                key=lambda x: x['date'],
                reverse=True
            )[:10]  # åªä¿ç•™æœ€è¿‘10ä¸ªcommit
        }

        if valid_commits >= CONFIG['OUTSTANDING_THRESHOLD']:
            outstanding.append(contributor)
        elif valid_commits >= CONFIG['EXCELLENT_THRESHOLD']:
            excellent.append(contributor)
        else:
            active.append(contributor)

    # æŒ‰æœ‰æ•ˆcommitæ•°é‡é™åºæ’åº
    outstanding.sort(key=lambda x: x['valid_commits'], reverse=True)
    excellent.sort(key=lambda x: x['valid_commits'], reverse=True)
    active.sort(key=lambda x: x['valid_commits'], reverse=True)

    return {
        'outstanding': outstanding,
        'excellent': excellent,
        'active': active
    }


def save_results(year, quarter, classified, stats, output_dir):
    """ä¿å­˜ç»Ÿè®¡ç»“æœåˆ°JSONæ–‡ä»¶"""
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # ç”Ÿæˆæ–‡ä»¶å
    filename = f"quarterly_contributors_{year}_Q{quarter}.json"
    output_file = output_dir / filename

    # å‡†å¤‡è¾“å‡ºæ•°æ®
    result = {
        'meta': {
            'year': year,
            'quarter': quarter,
            'generated_at': datetime.now().isoformat(),
            'total_contributors': len(stats),
            'outstanding_count': len(classified['outstanding']),
            'excellent_count': len(classified['excellent']),
            'active_count': len(classified['active']),
            'thresholds': {
                'outstanding': CONFIG['OUTSTANDING_THRESHOLD'],
                'excellent': CONFIG['EXCELLENT_THRESHOLD'],
                'valid_commit_threshold': CONFIG['VALID_COMMIT_THRESHOLD']
            }
        },
        'contributors': classified
    }

    # ä¿å­˜åˆ°æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    return output_file


def print_summary(classified):
    """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
    print("\n" + "="*60)
    print("ğŸ“Š ç»Ÿè®¡æ‘˜è¦")
    print("="*60)

    print(f"\nğŸ† å“è¶Šè´¡çŒ®è€… (>={CONFIG['OUTSTANDING_THRESHOLD']}æ¬¡æœ‰æ•ˆcommit): {len(classified['outstanding'])}äºº")
    for contributor in classified['outstanding'][:5]:
        print(f"  - {contributor['username']}: {contributor['valid_commits']}æ¬¡ ({contributor['repos_count']}ä¸ªä»“åº“)")

    print(f"\nâ­ ä¼˜ç§€è´¡çŒ®è€… (>={CONFIG['EXCELLENT_THRESHOLD']}æ¬¡æœ‰æ•ˆcommit): {len(classified['excellent'])}äºº")
    for contributor in classified['excellent'][:5]:
        print(f"  - {contributor['username']}: {contributor['valid_commits']}æ¬¡ ({contributor['repos_count']}ä¸ªä»“åº“)")

    print(f"\nğŸ‘¥ æ´»è·ƒè´¡çŒ®è€… (<{CONFIG['EXCELLENT_THRESHOLD']}æ¬¡æœ‰æ•ˆcommit): {len(classified['active'])}äºº")

    print("\n" + "="*60)


def cleanup_cache():
    """æ¸…ç†æ•´ä¸ªç¼“å­˜ç›®å½•"""
    cache_root = Path(__file__).parent.parent.parent / 'cache'
    try:
        if cache_root.exists():
            shutil.rmtree(cache_root)
            print(f"ğŸ—‘ï¸  ç¼“å­˜ç›®å½•å·²æ¸…ç†: {cache_root}")
            return True
    except Exception as e:
        print(f"âš ï¸  æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
    return False


def main(year, quarter):
    """
    ä¸»å‡½æ•°ï¼šç»Ÿè®¡æŒ‡å®šå­£åº¦çš„è´¡çŒ®è€…

    Args:
        year: å¹´ä»½
        quarter: å­£åº¦ (1-4)
    """
    print("="*60)
    print(f"ğŸš€ å¼€å§‹ç»Ÿè®¡ {year}å¹´ Q{quarter} å­£åº¦è´¡çŒ®è€…")
    print("="*60)

    # æ£€æŸ¥APIé€Ÿç‡é™åˆ¶
    if not check_rate_limit():
        print("âš ï¸  APIè°ƒç”¨æ¬¡æ•°ä¸è¶³ï¼Œå»ºè®®ç¨åå†è¯•")
        return

    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    cache_manager = CacheManager(CONFIG['CACHE_DIR'])
    print(f"ğŸ“¦ ç¼“å­˜å·²åŠ è½½: {cache_manager.size()} æ¡è®°å½•")

    # è·å–å­£åº¦æ—¥æœŸèŒƒå›´
    since, until = get_quarter_date_range(year, quarter)
    print(f"ğŸ“… ç»Ÿè®¡æ—¶é—´èŒƒå›´: {since} è‡³ {until}")

    # è·å–ç»„ç»‡ä»“åº“
    repos = get_org_repos(CONFIG['ORG_NAME'])
    if not repos:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•ä»“åº“")
        return

    # ç»Ÿè®¡æ•°æ®
    stats = {}
    total_commits = 0
    start_time = time.time()

    # å¤„ç†æ¯ä¸ªä»“åº“
    for i, repo in enumerate(repos):
        repo_name = repo['name']
        print(f"\n[{i+1}/{len(repos)}] å¤„ç†ä»“åº“: {repo_name}")

        try:
            commit_count = process_repository(
                CONFIG['ORG_NAME'],
                repo_name,
                since,
                until,
                cache_manager,
                stats
            )
            total_commits += commit_count

            # æ¯å¤„ç†10ä¸ªä»“åº“ä¿å­˜ä¸€æ¬¡ç¼“å­˜
            if (i + 1) % 10 == 0:
                cache_manager.save()

        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
            continue

    # ä¿å­˜æœ€ç»ˆç¼“å­˜
    cache_manager.save()

    # å¯¹è´¡çŒ®è€…è¿›è¡Œåˆ†çº§
    print("\nğŸ“Š æ­£åœ¨åˆ†çº§è´¡çŒ®è€…...")
    classified = classify_contributors(stats)

    # æ‰“å°æ‘˜è¦
    print_summary(classified)

    # ä¿å­˜ç»“æœ
    output_file = save_results(
        year,
        quarter,
        classified,
        stats,
        CONFIG['OUTPUT_DIR']
    )

    # æ˜¾ç¤ºæ‰§è¡Œç»Ÿè®¡
    elapsed_time = time.time() - start_time
    print(f"\nâ±ï¸  æ€»è€—æ—¶: {elapsed_time:.1f} ç§’")
    print(f"ğŸ“Š å¤„ç†ä»“åº“: {len(repos)} ä¸ª")
    print(f"ğŸ“Š æ€»commitæ•°: {total_commits}")
    print(f"ğŸ“Š æ€»è´¡çŒ®è€…: {len(stats)} äºº")

    # æ¸…ç†ç¼“å­˜ç›®å½•
    print("\nğŸ§¹ æ¸…ç†ç¼“å­˜...")
    cleanup_cache()

    print("\nâœ… ç»Ÿè®¡å®Œæˆï¼")
    return output_file


def get_previous_quarter():
    """
    è·å–ä¸Šä¸€ä¸ªå­£åº¦çš„å¹´ä»½å’Œå­£åº¦
    ä¾‹å¦‚ï¼šå½“å‰æ˜¯2026å¹´2æœˆ(Q1)ï¼Œè¿”å› (2025, 4)
    """
    now = datetime.now()
    current_quarter = (now.month - 1) // 3 + 1

    if current_quarter == 1:
        # å½“å‰æ˜¯Q1ï¼Œä¸Šå­£åº¦æ˜¯å»å¹´Q4
        return now.year - 1, 4
    else:
        # å…¶ä»–æƒ…å†µï¼Œä¸Šå­£åº¦æ˜¯ä»Šå¹´çš„å‰ä¸€ä¸ªå­£åº¦
        return now.year, current_quarter - 1


def get_current_quarter():
    """è·å–å½“å‰å­£åº¦çš„å¹´ä»½å’Œå­£åº¦"""
    now = datetime.now()
    current_quarter = (now.month - 1) // 3 + 1
    return now.year, current_quarter


if __name__ == '__main__':
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) == 1:
        # æ— å‚æ•°æ—¶æ˜¾ç¤ºå¸®åŠ©
        print("ç”¨æ³•:")
        print("  python quarterly_contributors.py --last      # ç»Ÿè®¡ä¸Šå­£åº¦")
        print("  python quarterly_contributors.py --current   # ç»Ÿè®¡å½“å‰å­£åº¦")
        print("  python quarterly_contributors.py <å¹´ä»½> <å­£åº¦>  # ç»Ÿè®¡æŒ‡å®šå­£åº¦")
        print("")
        print("ç¤ºä¾‹:")
        print("  python quarterly_contributors.py --last")
        print("  python quarterly_contributors.py 2025 4")
        sys.exit(0)

    try:
        if sys.argv[1] == '--last':
            # ç»Ÿè®¡ä¸Šå­£åº¦
            year, quarter = get_previous_quarter()
            print(f"ğŸ“… è‡ªåŠ¨é€‰æ‹©ä¸Šå­£åº¦: {year}å¹´ Q{quarter}")
            main(year, quarter)
        elif sys.argv[1] == '--current':
            # ç»Ÿè®¡å½“å‰å­£åº¦
            year, quarter = get_current_quarter()
            print(f"ğŸ“… è‡ªåŠ¨é€‰æ‹©å½“å‰å­£åº¦: {year}å¹´ Q{quarter}")
            main(year, quarter)
        elif len(sys.argv) >= 3:
            # æŒ‡å®šå¹´ä»½å’Œå­£åº¦
            year = int(sys.argv[1])
            quarter = int(sys.argv[2])

            if quarter not in [1, 2, 3, 4]:
                print("âŒ å­£åº¦å¿…é¡»æ˜¯ 1-4 ä¹‹é—´çš„æ•°å­—")
                sys.exit(1)

            main(year, quarter)
        else:
            print("âŒ å‚æ•°ä¸è¶³ï¼Œè¯·ä½¿ç”¨ --last æˆ–æŒ‡å®šå¹´ä»½å’Œå­£åº¦")
            sys.exit(1)

    except ValueError:
        print("âŒ å‚æ•°æ ¼å¼é”™è¯¯ï¼Œå¹´ä»½å’Œå­£åº¦å¿…é¡»æ˜¯æ•°å­—")
        sys.exit(1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
